# Data_science_final_project
final dessertaion University of Hertfordshire (23022047)

# Enhancing Image Classification with Vision Transformers
Project Summary:
This project explores the self-attention mechanism in Vision Transformers (ViT) and its impact on the performance of image classification tasks, especially compared to traditional Convolutional Neural Networks (CNNs). CNNs, while successful, rely heavily on convolutions and pooling operations, which can limit the model’s ability to capture long-range dependencies. In contrast, ViT models utilize a self-attention mechanism that processes the entire image globally, enabling them to potentially learn more complex features and relationships across an image. By investigating how the self-attention mechanism enhances performance, this project aims to understand the advantages and limitations of ViT in comparison to CNNs for image classification tasks.

Research Question:
How does the self-attention mechanism in Vision Transformers (ViT) enhance the performance of image classification tasks compared to traditional Convolutional Neural Networks (CNNs)? What are the pros and cons of ViTs compared to CNNs in terms of dataset size, training complexity, computational resources, and the ability to understand the context of an image?

Project Objectives:
1.	To analyze the fundamental differences between Vision Transformers (ViTs) and Convolutional Neural Networks (CNNs).
2.	To investigate the performance of ViTs on various image classification benchmarks and compare them to CNN-based models.
3.	To examine the pros and cons of using ViTs in terms of dataset size, computational requirements, and their ability to capture image context.
4.	To develop a comprehensive understanding of how ViTs can outperform CNNs in image classification tasks, especially for larger, more complex datasets.

Reference List:
• Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. A., Kaiser, Ł., & Polosukhin, I. (2017). Title: Attention is All You Need. 
• Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Title: ImageNet Classification with Deep Convolutional Neural Networks. 
• Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby. Title: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.
Data Management Plan:
