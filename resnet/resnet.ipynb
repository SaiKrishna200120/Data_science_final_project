{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install dependencies and imports"
      ],
      "metadata": {
        "id": "lZ72D0TtVBrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, roc_curve, auc\n",
        "from thop import profile\n",
        "import pandas as pd\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "WiXJBlwYEcx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "RzoOBUJoVC5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 50\n",
        "batch_size = 128\n",
        "learning_rate = 0.1\n",
        "momentum = 0.9\n",
        "weight_decay = 5e-4"
      ],
      "metadata": {
        "id": "Oi5li9HpEliu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define BasicBlock for ResNet"
      ],
      "metadata": {
        "id": "X24dOJx_VETy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic block for ResNet\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Shortcut connection\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "XPY3rUTTErcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet Architecture\n"
      ],
      "metadata": {
        "id": "ctiM6CjJVFzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet Architecture\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        # Initial convolution before the blocks\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # ResNet blocks\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "\n",
        "        # Final classification layer\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "# ResNet-18\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])"
      ],
      "metadata": {
        "id": "lu1y68zdE9RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading and Preprocessing\n"
      ],
      "metadata": {
        "id": "8rV7PwE2VG_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and normalize CIFAR10\n",
        "print(\"Preparing data...\")\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "metadata": {
        "id": "Ru7bC5sYFJDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Setup\n"
      ],
      "metadata": {
        "id": "Ul40zRpUVI-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model setup\n",
        "model = ResNet18().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
        "\n",
        "# Calculate parameters and FLOPs\n",
        "print(\"Calculating model parameters and FLOPs...\")\n",
        "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
        "flops, params = profile(model, inputs=(dummy_input,))\n",
        "print(f\"Number of parameters: {params:,}\")\n",
        "print(f\"Number of FLOPs: {flops:,}\")\n",
        "\n",
        "# Lists to store metrics\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "epoch_times = []\n",
        "batch_times = []\n",
        "learning_rates = []\n"
      ],
      "metadata": {
        "id": "Z83EIVN-FSPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Function\n"
      ],
      "metadata": {
        "id": "LJfdTjxzVKWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    epoch_start_time = time.time()\n",
        "    batch_times_epoch = []\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        batch_start_time = time.time()\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        batch_end_time = time.time()\n",
        "        batch_times_epoch.append(batch_end_time - batch_start_time)\n",
        "\n",
        "        if batch_idx % 100 == 99:    # Print every 100 mini-batches\n",
        "            print(f'Epoch: {epoch+1}, Batch: {batch_idx+1}, Loss: {running_loss/100:.3f}, Acc: {100.*correct/total:.3f}%')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - epoch_start_time\n",
        "    avg_batch_time = sum(batch_times_epoch) / len(batch_times_epoch)\n",
        "\n",
        "    train_loss = running_loss / len(trainloader)\n",
        "    train_accuracy = 100. * correct / total\n",
        "\n",
        "    print(f'Epoch {epoch+1} complete. Time taken: {epoch_time:.2f}s, Avg Batch Time: {avg_batch_time:.4f}s')\n",
        "\n",
        "    return train_loss, train_accuracy, epoch_time, avg_batch_time\n"
      ],
      "metadata": {
        "id": "gBpBHrGmFcMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing Function\n"
      ],
      "metadata": {
        "id": "s00zE9mRVLaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing function\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    class_probs = {i: [] for i in range(10)}  # For ROC curves\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in testloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # Store predictions and targets for confusion matrix and per-class metrics\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "            # Store probabilities for ROC curve\n",
        "            probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
        "            for i in range(10):\n",
        "                class_probs[i].extend(probs[:, i])\n",
        "\n",
        "    test_loss = test_loss / len(testloader)\n",
        "    test_accuracy = 100. * correct / total\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_accuracy:.3f}%')\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(all_targets, all_preds)\n",
        "\n",
        "    # Calculate per-class metrics\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_preds, average=None)\n",
        "\n",
        "    # Calculate ROC curves\n",
        "    fpr = {}\n",
        "    tpr = {}\n",
        "    roc_auc = {}\n",
        "    for i in range(10):\n",
        "        # Convert to binary classification problem for each class\n",
        "        binary_targets = [1 if t == i else 0 for t in all_targets]\n",
        "        binary_probs = class_probs[i]\n",
        "\n",
        "        # Calculate ROC curve\n",
        "        fpr[i], tpr[i], _ = roc_curve(binary_targets, binary_probs)\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    return test_loss, test_accuracy, cm, precision, recall, f1, fpr, tpr, roc_auc"
      ],
      "metadata": {
        "id": "bMwhDxJxFqaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Training Loop"
      ],
      "metadata": {
        "id": "SeRax95EVMbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training loop\n",
        "print(\"Starting training...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    learning_rates.append(current_lr)\n",
        "\n",
        "    # Train for one epoch\n",
        "    train_loss, train_accuracy, epoch_time, avg_batch_time = train(epoch)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    epoch_times.append(epoch_time)\n",
        "    batch_times.append(avg_batch_time)\n",
        "\n",
        "    # Test the model\n",
        "    test_loss, test_accuracy, cm, precision, recall, f1, fpr, tpr, roc_auc = test(epoch)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Update learning rate based on validation loss\n",
        "    scheduler.step(test_loss)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs} - '\n",
        "          f'LR: {current_lr:.6f}, '\n",
        "          f'Train Loss: {train_loss:.4f}, '\n",
        "          f'Train Acc: {train_accuracy:.2f}%, '\n",
        "          f'Test Loss: {test_loss:.4f}, '\n",
        "          f'Test Acc: {test_accuracy:.2f}%')\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "id": "rWDBVhtSFv_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Metrics"
      ],
      "metadata": {
        "id": "1bcqAuK2VNaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot metrics\n",
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "# Plot loss curves\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, num_epochs+1), test_losses, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Epoch vs Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot accuracy curves\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(range(1, num_epochs+1), train_accuracies, label='Train Accuracy')\n",
        "plt.plot(range(1, num_epochs+1), test_accuracies, label='Test Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Epoch vs Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot confusion matrix (using the last epoch's results)\n",
        "plt.subplot(2, 3, 3)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n"
      ],
      "metadata": {
        "id": "6te1ycbVFycg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More Plots"
      ],
      "metadata": {
        "id": "AJPS7S2QVONW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot per-class metrics (using the last epoch's results)\n",
        "plt.subplot(2, 3, 4)\n",
        "x = np.arange(len(classes))\n",
        "width = 0.2\n",
        "plt.bar(x - width, precision, width, label='Precision')\n",
        "plt.bar(x, recall, width, label='Recall')\n",
        "plt.bar(x + width, f1, width, label='F1-Score')\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Performance per Class')\n",
        "plt.xticks(x, classes, rotation=45)\n",
        "plt.legend()\n",
        "\n",
        "# Plot ROC curves (using the last epoch's results)\n",
        "plt.subplot(2, 3, 5)\n",
        "for i in range(10):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'{classes[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve per Class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Plot epoch times and learning rate\n",
        "plt.subplot(2, 3, 6)\n",
        "fig, ax1 = plt.subplots()\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Time (s)', color=color)\n",
        "ax1.plot(range(1, num_epochs+1), epoch_times, color=color, label='Epoch Time')\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Learning Rate', color=color)\n",
        "ax2.plot(range(1, num_epochs+1), learning_rates, color=color, label='Learning Rate')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.title('Epoch Training Time & Learning Rate')\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.savefig('resnet18_metrics.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LSCw7P6PGAiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Statistics Table and Save Model"
      ],
      "metadata": {
        "id": "NNMTXBDEVO1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a table of training statistics\n",
        "stats_df = pd.DataFrame({\n",
        "    'Epoch': range(1, num_epochs+1),\n",
        "    'Train Loss': train_losses,\n",
        "    'Test Loss': test_losses,\n",
        "    'Train Accuracy': train_accuracies,\n",
        "    'Test Accuracy': test_accuracies,\n",
        "    'Epoch Time (s)': epoch_times,\n",
        "    'Avg Batch Time (s)': batch_times,\n",
        "    'Learning Rate': learning_rates\n",
        "})\n",
        "\n",
        "print(\"\\nTraining Statistics:\")\n",
        "print(stats_df.to_string(index=False))\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'resnet18_cifar10.pth')\n",
        "print(\"Model saved to 'resnet18_cifar10.pth'\")"
      ],
      "metadata": {
        "id": "-nSGqsDAGQkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Evaluation Report"
      ],
      "metadata": {
        "id": "8uxNVvuUVQhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation report\n",
        "print(\"\\nFinal Model Evaluation:\")\n",
        "print(f\"Model: ResNet-18\")\n",
        "print(f\"Dataset: CIFAR-10\")\n",
        "print(f\"Number of parameters: {params:,}\")\n",
        "print(f\"Number of FLOPs: {flops:,}\")\n",
        "print(f\"Best test accuracy: {max(test_accuracies):.2f}%\")\n",
        "print(f\"Final test accuracy: {test_accuracies[-1]:.2f}%\")\n",
        "print(f\"Average epoch training time: {sum(epoch_times)/len(epoch_times):.2f}s\")\n",
        "print(f\"Average batch processing time: {sum(batch_times)/len(batch_times):.4f}s\")\n"
      ],
      "metadata": {
        "id": "X5NPlsOtGGbK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}